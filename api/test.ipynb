{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"clarity_score\": string  // score of clarity of learner\\'s explanation\\n\\t\"clarity_explanation\": string  // explanation of clarity score given\\n\\t\"conciseness_score\": string  // score of conciseness of learner\\'s explanation\\n\\t\"conciseness_explanation\": string  // explanation of conciseness score given\\n\\t\"comprehensiveness_score\": string  // score of comprehensiveness of learner\\'s explanation\\n\\t\"comprehensiveness_explanation\": string  // explanation of comprehensiveness score given\\n\\t\"correctness_score\": string  // score of correctness of learner\\'s explanation\\n\\t\"correctness_explanation\": string  // explanation of correctness score given\\n}\\n```'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_schemas = [\n",
    "    ResponseSchema(name=\"clarity_score\", description=\"score of clarity of learner's explanation\"),\n",
    "    ResponseSchema(name=\"clarity_explanation\", description=\"explanation of clarity score given\"),\n",
    "    ResponseSchema(name=\"conciseness_score\", description=\"score of conciseness of learner's explanation\"),\n",
    "    ResponseSchema(name=\"conciseness_explanation\", description=\"explanation of conciseness score given\"),\n",
    "    ResponseSchema(name=\"comprehensiveness_score\", description=\"score of comprehensiveness of learner's explanation\"),\n",
    "    ResponseSchema(name=\"comprehensiveness_explanation\", description=\"explanation of comprehensiveness score given\"),\n",
    "    ResponseSchema(name=\"correctness_score\", description=\"score of correctness of learner's explanation\"),\n",
    "    ResponseSchema(name=\"correctness_explanation\", description=\"explanation of correctness score given\"),\n",
    "]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "format_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clarity_score': '4.8',\n",
       " 'clarity_explanation': 'The learner provided a clear and detailed explanation of merge sort. They effectively described the process of dividing the list, sorting the smaller lists, and merging them back together. However, there were a few instances where the learner could have used more precise language to describe the process.',\n",
       " 'conciseness_score': '4.5',\n",
       " 'conciseness_explanation': \"The learner's explanation was mostly concise. However, they occasionally included extra information or repeated certain points, which slightly detracted from the conciseness of their explanation.\",\n",
       " 'comprehensiveness_score': '5',\n",
       " 'comprehensiveness_explanation': \"The learner's explanation covered all aspects of merge sort, including how it works, its time complexity, and how it compares to other sorting algorithms. They also discussed potential drawbacks of merge sort, such as its memory usage.\",\n",
       " 'correctness_score': '5',\n",
       " 'correctness_explanation': 'The information provided by the learner about merge sort was accurate. They correctly described how merge sort works, its time complexity, and its advantages and disadvantages compared to other sorting algorithms.'}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"You are a helpful assistant that takes a transcript and scores the learner's explanation to the agent and provides a detailed explanation using the evidence available. You will score using this rubric: {rubric} and you can use the agent's response to support your case but remember that you are scoring the learner's explanations. \\n{format_instructions}\\n{question}\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"answer the users question as best as possible.\\n{format_instructions}\\n{question}\",\n",
    "    input_variables=[\"question\", \"rubric\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "with open('./conversation_data.json', 'r') as file:\n",
    "    conversation = json.load(file)\n",
    "    _input = prompt.format_prompt(question=conversation, rubric=constants.marking_rubric)\n",
    "\n",
    "chat_model = ChatOpenAI(model=\"gpt-4\", openai_api_key=openai_key)\n",
    "output = chat_model(_input.to_messages())\n",
    "output_parser.parse(output.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
